{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbf8d99f-fa22-4253-bb18-b40813d5e32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84c92ef9-dd79-4874-878b-431e94842568",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(1, os.path.abspath('../py'))\n",
    "from nt_utils import TranscriptionUtilities\n",
    "\n",
    "tu = TranscriptionUtilities(\n",
    "    data_folder_path=os.path.abspath('../data'),\n",
    "    saves_folder_path=os.path.abspath('../saves')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e39fb0-12d6-41f1-a48b-f6a22fead489",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "## Here's a manual transcription of the first few paragraphs of \"The Coming Thresholds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a54a285-0ce8-4d26-93db-f9bc4562b357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome everyone! This is not a \"Voices with Vervaeke\", this is a new entity I'm calling a video essay. But (under good advice from the two gentlemen that are joining me) it was proposed to me, and I accept the proposal, that this should have a little bit more of a dialogical structure to it. And, given the value of dialogue as I've been explaining it in other work, I took this deeply to heart.\n",
      "\n",
      "I am going to present, still, an essay. And let's remember what Montaigne meant by *essai*: \"to try\". I'm going to \"try\" with the help of these two gentlemen to bring some clarity to the issue around GPT machines the advent of what looks like this for \"sparks\" of Artificial General Intelligence.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path = os.path.join(tu.saves_text_folder, 'AI_The_Coming_Thresholds_and_The_Path_We_Must_Take_Internationally_Acclaimed_Cognitive_Scientist.txt')\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    essay_str = '\\n\\n'.join(f.read().split('\\n\\n')[1:3])\n",
    "print(essay_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1612f7a0-8c0d-444c-8b29-98b6688e6377",
   "metadata": {},
   "source": [
    "\n",
    "## Let's try taking the YouTube transcription and cleaning it up with an offline LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "008b6c85-cf19-4380-96f6-ad7e644240bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the transcription for the video\n",
    "tu.ensure_module_installed('youtube-transcript-api', upgrade=True, verbose=False)\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "video_id = 'A-_RdKiDbz4'\n",
    "transcript_dicts_list = YouTubeTranscriptApi.get_transcript(video_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e780e7b-27f0-4d20-b55e-645d427b96ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': \"Could you break up this wall of text (using capitalization, punctuation, and whitespace) into sentences and paragraphs so that it is easier to read? Do this without paraphrasing the text. Only remove filler words, discourse markers, repetitions, and other thinking noises.\\n\\nwelcome everyone this is not a voices with friviki this is a new entity i'm calling a video essay but under good advice from the two gentlemen that are joining me it was proposed to me and i accept the proposal that this should have a little bit more of a dialogical uh structure to it and given the value of dialogue as i've been explaining it in other work i took this deeply to heart i am going to present still an essay and let's remember what montana meant by essay saa to try i'm going to try with the help of these two gentlemen to bring some clarity to the issue around gpt machines the advent of what looks like this for sparks of artificial general intelligence\"}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Prepare the prompt\n",
    "tu.ensure_module_installed('gpt4all', verbose=False)\n",
    "import gpt4all\n",
    "\n",
    "file_path = os.path.join(tu.saves_text_folder, 'break_this_up.txt')\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    prompt_str = f.read()\n",
    "messages = [{'role': 'user', 'content': prompt_str + '\\n\\n' + ' '.join([transcript_dict['text'] for transcript_dict in transcript_dicts_list][:20]).lower()}]\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1e82fe1-383a-4fb1-8abb-a56b6c4d6eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best offline model is ggml-wizardLM-7B.q4_2.bin\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get the best offline model\n",
    "if tu.pickle_exists('models_df'):\n",
    "    models_df = tu.load_object('models_df', verbose=False)\n",
    "    mask_series = (models_df.usage_completion_tokens > 0)\n",
    "    best_model = models_df[mask_series].sort_values('similarity', ascending=False).head(1).model_name.squeeze()\n",
    "else:\n",
    "    best_model = 'ggml-wizardLM-7B.q4_2.bin'\n",
    "print(f'The best offline model is {best_model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8d0df94-72e1-48b7-a87f-b6d298a2f303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file.\n",
      "Sure, I can help with that. Here's the text broken up into sentences and paragraphs:\n",
      "\n",
      "Welcome everyone, this is not a Voices with Friviki. This is a new entity I'm calling a video essay. Under good advice from the two gentlemen that are joining me, it was proposed to me, and I accept the proposal that this should have a little bit more of a dialogical uh structure to it. Given the value of dialogue as I've been explaining it in other work, I took this deeply to heart. I am going to present still an essay, and let's remember what Montana meant by essay saa to try. I'm going to try with the help of these two gentlemen to bring some clarity to the issue around GPT machines, the advent of what looks like this for sparks of artificial general intelligence.\n",
      "ggml-wizardLM-7B.q4_2.bin responded in 30 minutes and 37 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get the model's response\n",
    "tu.ensure_module_installed('humanize', verbose=False)\n",
    "import time\n",
    "import humanize\n",
    "\n",
    "t1 = time.time()\n",
    "model_obj = gpt4all.GPT4All(best_model, model_path=tu.data_models_folder)\n",
    "\n",
    "# n_predict is the number of tokens to predict. It defaults to 128 for this LLModel.\n",
    "response_dict = model_obj.chat_completion(messages, verbose=False, n_predict=256)\n",
    "\n",
    "print(response_dict['choices'][0]['message']['content'])\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "print(f'{best_model} responded in {duration_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15ae7e3c-604f-4762-80fc-283c591f2786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.771978021978022"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tu.similar(essay_str, response_dict['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ce3939-523b-4016-84f6-42de97053aa3",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "## Let's try taking the YouTube transcription and cleaning it up with an online LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ac12fda-1df1-4b10-bd82-9b313afbca67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Welcome everyone! This is not Voices with Friviki, this is a new entity I'm calling a video essay. Under good advice from the two gentlemen joining me, it was proposed to me and I accepted the proposal that this should have a little bit more of a dialogical structure. Given the value of dialogue as I've been explaining it in other work, I took this deeply to heart. \n",
      "\n",
      "I am going to present still an essay and, let's remember what Montana meant by \"essay\": to try. With the help of these two gentlemen, I'm going to try to bring some clarity to the issue around GPT machines and the advent of what looks like sparks of artificial general intelligence.\n",
      "OpenAI responded in 7 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tu.ensure_module_installed('langchain', verbose=False)\n",
    "t1 = time.time()\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0.9)\n",
    "openai_response_str = llm(messages[0]['content'])\n",
    "print(openai_response_str)\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "print(f'OpenAI responded in {duration_str}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1872f5-d3dc-4288-b982-eadb60c869f7",
   "metadata": {},
   "source": [
    "\n",
    "That's almost twenty times faster!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec7f62b8-c734-4cbf-abe9-e6b4b9fba309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4966641957005189"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tu.similar(essay_str, openai_response_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c3506c-95da-4186-9310-235a5f9e03eb",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "## Let's try downloading the audio as an mp3 and text-to-speeching it ourselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93cf8aff-04f3-464b-ab48-f4f6afcff920",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_file = 'AI_The_Coming_Thresholds_and_The_Path_We_Must_Take_Internationally_Acclaimed_Cognitive_Scientist.mp3'\n",
    "new_path = os.path.join(tu.saves_mp3_folder, new_file)\n",
    "if not os.path.exists(new_path):\n",
    "    tu.ensure_module_installed('pytube', upgrade=True, verbose=False)\n",
    "    from pytube import YouTube\n",
    "    import re\n",
    "\n",
    "    video_url = f'https://www.youtube.com/watch?v={video_id}'\n",
    "    yt = YouTube(video_url)\n",
    "\n",
    "    # Extract audio with 160kbps quality from video\n",
    "    video = yt.streams.filter(abr='160kbps').last()\n",
    "\n",
    "    # Download the file\n",
    "    out_path = video.download(output_path=tu.saves_mp3_folder)\n",
    "    os.rename(out_path, new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98607724-b4c2-4af6-85af-a6347a32ba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tu.ensure_module_installed('pydub', upgrade=True, verbose=False)\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Files\n",
    "dst_path = os.path.join(tu.saves_wav_folder, os.path.splitext(new_file)[0] + '.wav')\n",
    "dst_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e48aba-a279-4a9f-b485-a13f273ba312",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert mp3 to wav\n",
    "sound = AudioSegment.from_mp3(new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cdd1bc-af88-4de7-ab77-fa853a8bd4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert mp3 to wav\n",
    "sound.export(dst_path, format='wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80b8f7e-cc0d-4504-9bd5-5d95cb15ee8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import library\n",
    "tu.ensure_module_installed('SpeechRecognition', upgrade=True, verbose=False)\n",
    "tu.ensure_module_installed('pyaudio', upgrade=True, verbose=False)\n",
    "tu.ensure_module_installed('pyttsx3', upgrade=True, verbose=False)\n",
    "import speech_recognition as sr\n",
    "\n",
    "# Initialize recognizer class (for recognizing the speech)\n",
    "r = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381aa21f-b88a-4a36-9510-b97d20ac76df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reading Audio file as source\n",
    "# listening the audio file and store in audio_text variable\n",
    "with sr.AudioFile(new_path) as source:\n",
    "    audio_text = r.listen(source, timeout=60, phrase_time_limit=60)\n",
    "    text = r.recognize_google(audio_text)\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de976af8-f176-4fb7-b620-68080326c256",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importing libraries\n",
    "import tempfile\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "\n",
    "# Initialize recognizer class (for recognizing the speech)\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# Recognize speech in the audio file so that we\n",
    "# don't repeat ourselves in other functions\n",
    "def transcribe_audio(path):\n",
    "    \n",
    "    # Use the audio file as the audio source\n",
    "    # Listen to the audio file and store it in the audio_text variable\n",
    "    with sr.AudioFile(path) as source:\n",
    "        audio_listened = r.record(source)\n",
    "        \n",
    "        # Attempt to convert it to text\n",
    "        text = r.recognize_google(audio_listened)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Split the audio file into chunks on\n",
    "# silence and apply speech recognition\n",
    "def get_large_audio_transcription_on_silence(path, verbose=True):\n",
    "    '''Splitting the large audio file into chunks\n",
    "    and apply speech recognition on each of these chunks'''\n",
    "    whole_texts_list = []\n",
    "    \n",
    "    # Open the audio file using pydub\n",
    "    sound = AudioSegment.from_file(path) \n",
    "    \n",
    "    # Split audio sound where silence is 500 miliseconds or more and get chunks\n",
    "    chunks = split_on_silence(\n",
    "        sound,\n",
    "        min_silence_len = 500, # experiment with this value for your target audio file\n",
    "        silence_thresh = sound.dBFS-14, # adjust this per requirement\n",
    "        keep_silence=500, # keep the silence for 1 second, adjustable as well\n",
    "    )\n",
    "    \n",
    "    # Create a directory to store the audio chunks\n",
    "    with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "        if verbose: print('created temporary directory', tmpdirname)\n",
    "        if not os.path.isdir(tmpdirname):\n",
    "            os.mkdir(tmpdirname)\n",
    "\n",
    "        # Process each chunk\n",
    "        for i, audio_chunk in enumerate(chunks, start=1):\n",
    "\n",
    "            # Export audio chunk and save it in\n",
    "            # the temporary directory.\n",
    "            chunk_filename = os.path.join(tmpdirname, f'chunk{i}.wav')\n",
    "            audio_chunk.export(chunk_filename, format='wav')\n",
    "\n",
    "            # Recognize the chunk\n",
    "            try:\n",
    "                text = transcribe_audio(chunk_filename)\n",
    "            except sr.UnknownValueError as e:\n",
    "                print('Error:', str(e))\n",
    "            except Exception as e:\n",
    "                print(f'{e.__class__.__name__} error: {str(e).strip()}')\n",
    "            else:\n",
    "                whole_texts_list.append(text)\n",
    "                if verbose: print(chunk_filename, ':', f'{text.capitalize()}. ')\n",
    "    \n",
    "    # Return the text for all chunks detected\n",
    "    return whole_texts_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e627de1-20b6-4951-810f-5b210c855be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "whole_text = ' '.join(get_large_audio_transcription_on_silence(dst_path, verbose=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d82d5ae-6902-4798-84b4-ee191480a894",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6d0fe1-14a1-4b4c-ba2f-454511678b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tu.ensure_module_installed('pathlib', verbose=False)\n",
    "tu.ensure_module_installed('langchain', verbose=False)\n",
    "tu.ensure_module_installed('google-api-python-client', verbose=False)\n",
    "tu.ensure_module_installed('google-auth-httplib2', verbose=False)\n",
    "tu.ensure_module_installed('google-auth-oauthlib', verbose=False)\n",
    "tu.ensure_module_installed('youtube_transcript_api', verbose=False)\n",
    "from pathlib import Path\n",
    "from langchain.document_loaders import GoogleApiClient\n",
    "from langchain.document_loaders import GoogleApiYoutubeLoader\n",
    "\n",
    "google_api_client = GoogleApiClient(\n",
    "    service_account_path=Path('../data/secrets/google_client_secrets.json')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1116f2-9cb2-43ef-8d20-8e1e090a1fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loader = GoogleApiYoutubeLoader(\n",
    "    google_api_client=google_api_client,\n",
    "    video_ids=[video_id]\n",
    ")\n",
    "documents_list = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ad7bfb-ccd1-49c5-ab3f-0a16ac1a0f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Document_obj = documents_list[0]\n",
    "dir(Document_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3c7eb5-371a-41b2-8f2f-fb2190f6a0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Document_obj.page_content[:671]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534aeee3-962a-4e88-a95f-b23a3c0a44ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tu.ensure_module_installed('youtube_dl', upgrade=True, verbose=False)\n",
    "from youtube_dl import YoutubeDL\n",
    "\n",
    "audio_downloder = YoutubeDL({'format':'bestaudio'})\n",
    "audio_downloder.extract_info(video_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a6fe3a-7e12-40c4-8509-d98a40dd5915",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tu.ensure_module_installed('youtube_dl', upgrade=True, verbose=False)\n",
    "import youtube_dl\n",
    "\n",
    "video_info = youtube_dl.YoutubeDL().extract_info(\n",
    "    url=video_url,\n",
    "    download=False\n",
    ")\n",
    "title = video_info['title']\n",
    "filename = f'{title}.mp3'\n",
    "options={\n",
    "    'format':'bestaudio/best',\n",
    "    'keepvideo':False,\n",
    "    'outtmpl':filename,\n",
    "}\n",
    "with youtube_dl.YoutubeDL(options) as ydl:\n",
    "    ydl.download([video_info['webpage_url']])\n",
    "print('Download complete... {}'.format(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5161b7-f841-4509-82ca-20dcf7797311",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a2a464a-2feb-42f7-a144-2644cc78cabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name: ggml-wizardLM-7B.q4_2.bin\n",
      "md5sum: 99e6d129745a3f1fb1121abed747b05a\n",
      "filesize: 4212864640\n",
      "description: A non-commercially licensable model based on Llama 7b and trained by Microsoft and Peking University.\n",
      "model: ggml-wizardLM-7B.q4_2\n",
      "usage_prompt_tokens: 1171.0\n",
      "usage_completion_tokens: 514.0\n",
      "usage_total_tokens: 1685.0\n",
      "choices_message_role: assistant\n",
      "choices_message_content: Sure, I can help with that. Here's the text broken up into sentences and paragraphs:\n",
      "\n",
      "Welcome everyone, this is not a Voices with Friviki. This is a new entity I'm calling a video essay. Under good advice from the two gentlemen that are joining me, it was proposed to me, and I accept the proposal that this should have a little bit more of a dialogical uh structure to it. Given the value of dialogue as I've been explaining it in other work, I took this deeply to heart. I am going to present still an essay, and\n",
      "similarity: 0.6071133167907361\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mask_series = (models_df.model_name == best_model)\n",
    "for row_index, row_series in models_df[mask_series].T.dropna().items():\n",
    "    for column_name, column_value in row_series.items():\n",
    "        print(column_name, column_value, sep=': ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPT Stuff (Python 3.10.10)",
   "language": "python",
   "name": "gs_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
